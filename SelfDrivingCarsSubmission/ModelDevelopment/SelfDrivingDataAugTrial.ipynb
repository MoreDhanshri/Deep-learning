{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import numpy as np\n",
    "import scipy.misc\n",
    "import random\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import model_from_json\n",
    "\n",
    "\n",
    "# In[7]:\n",
    "\n",
    "np.random.seed(123) \n",
    "\n",
    "\n",
    "# In[8]:\n",
    "\n",
    "xs = []\n",
    "ys = []\n",
    "\n",
    "#points to the end of the last batch\n",
    "train_batch_pointer = 0\n",
    "val_batch_pointer = 0\n",
    "\n",
    "#read data.txt\n",
    "\n",
    "        \n",
    "def generate_arrays_from_file(path):\n",
    "    while 1:\n",
    "        f = open(path)\n",
    "        for line in f:\n",
    "            # create numpy arrays of input data\n",
    "            # and labels, from each line in the file\n",
    "            x_out = []\n",
    "            y_out = []\n",
    "            xs=\"driving_dataset/\" + line.split()[0]\n",
    "            img=scipy.misc.imresize(scipy.misc.imread(xs),[66, 200]).astype('float32')/255\n",
    "            x_out.append(img)\n",
    "            y=float(line.split()[1]) * scipy.pi / 180\n",
    "            y_out.append(y)\n",
    "            #x, y = process_line(line)\n",
    "            #img = load_images(x)\n",
    "            yield (img, y)\n",
    "        f.close()\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In[9]:\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Convolution2D(64, 3, 3, input_shape=(60, 80,3), border_mode='same', activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Convolution2D(64, 3, 3, activation='relu', border_mode='same'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "model.add(Convolution2D(128, 3, 3, activation='relu', border_mode='same'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1))\n",
    "\n",
    "\n",
    "\n",
    "# In[10]:\n",
    "\n",
    "model.compile(optimizer=Adam(lr=1e-4), loss = 'mse')\n",
    "filepath=\"weights.best.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model.fit_generator(generate_arrays_from_file('driving_dataset/data.txt'),callbacks=callbacks_list,\n",
    "        samples_per_epoch=10000,epochs=10, verbose=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
